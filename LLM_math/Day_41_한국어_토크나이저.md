# Day 41: 한국어 토크나이저 (1.5시간)

## 📚 학습 목표
- 한국어 토큰화의 특수성 이해하기
- 음절 vs 자모 분리 파악하기
- 한국어 LLM을 위한 전략 수립하기

---

## 🎯 강의 주제
**"한국어 특화 토크나이저"**

---

## 📖 핵심 개념

### 1. 한국어의 특수성

**교착어 (Agglutinative)**:
```
먹다 → 먹고, 먹어서, 먹었다, 먹을
→ 형태소 조합이 매우 다양
```

**음절 vs 자모**:
```
음절: '한국어' = 3토큰
자모: 'ㅎㅏㄴㄱㅜㄱㅇㅓ' = 7토큰

어느 것이 효율적?
```

---

### 2. 전략들

**1. 음절 기반 BPE**:
```
- 간단, 효과적
- GPT-3처럼 바이트 레벨도 가능
```

**2. 형태소 분석 + BPE**:
```
- '먹었다' → '먹/VV + 었/EP + 다/EF'
- 더 정확하지만 복잡
```

**3. 자모 분리 + BPE**:
```
- '한글' → 'ㅎㅏㄴㄱㅡㄹ'
- 미등록 단어 없음
- 시퀀스 길어짐
```

---

## 💻 Python 실습

```python
# 간단한 한국어 음절 BPE
corpus_kr = "안녕하세요 안녕 하세요 반갑습니다"

# BPE 학습 (음절 단위)
print("=== 한국어 BPE ===\n")
print(f"말뭉치: {corpus_kr}\n")

# 음절로 분리
words = corpus_kr.split()
print("음절 분리:")
for word in words:
    syllables = ' '.join(word)
    print(f"  {word} → {syllables}")

print("\nBPE 적용 후:")
print("  안녕 → 하나의 토큰")
print("  하세요 → 하나의 토큰")
```

---

## 🔗 한국어 LLM

### 주요 모델들
```
- KoGPT (SKT): BPE
- KoBERT (SKT): SentencePiece
- Polyglot-Ko: SentencePiece + 자모 고려
```

### 당신의 프로젝트
```
목표: 한국어 특화 토크나이저 개발

고려사항:
1. 음절 vs 자모
2. 어휘 크기
3. 형태소 정보 활용
4. 효율성 (압축률)
```

---

## 🎓 핵심 요약

**한국어는 독특한 도전**
- 교착어 특성
- 음절 구조
- 형태소 풍부

**해결책**:
- SentencePiece + 적절한 전처리
- 한국어 특성 고려한 BPE

### 다음 학습
- **Day 42**: 토크나이저 프로젝트

---

**한국어 LLM의 핵심은 토크나이저입니다!**
