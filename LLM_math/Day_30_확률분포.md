# Day 30: í™•ë¥ ë¶„í¬ (1.5ì‹œê°„)

## ğŸ“š í•™ìŠµ ëª©í‘œ
- í™•ë¥ ë¶„í¬ì˜ ê°œë… ì´í•´í•˜ê¸°
- ì •ê·œë¶„í¬ì˜ ì„±ì§ˆ íŒŒì•…í•˜ê¸°
- í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°í•˜ê¸°

---

## ğŸ¯ ê°•ì˜ ì£¼ì œ
**"í™•ë¥ ì´ ì–´ë–»ê²Œ ë¶„í¬í•˜ëŠ”ê°€?"**

---

## ğŸ“– í•µì‹¬ ê°œë…

### 1. í™•ë¥ ë¶„í¬
```
P(X = x): Xê°€ xì¼ í™•ë¥ 

ì´ì‚°: P(X = 1), P(X = 2), ...
ì—°ì†: í™•ë¥ ë°€ë„í•¨ìˆ˜ f(x)
```

### 2. ì •ê·œë¶„í¬ (Gaussian)
```
N(Î¼, ÏƒÂ²)

Î¼: í‰ê·  (mean)
ÏƒÂ²: ë¶„ì‚° (variance)
Ïƒ: í‘œì¤€í¸ì°¨ (standard deviation)

f(x) = (1/âˆš(2Ï€ÏƒÂ²)) Ã— exp(-(x-Î¼)Â²/(2ÏƒÂ²))
```

### 3. í‰ê· ê³¼ ë¶„ì‚°
```
í‰ê· : E[X] = Î£ x Ã— P(X=x)
ë¶„ì‚°: Var(X) = E[(X-Î¼)Â²]
í‘œì¤€í¸ì°¨: Ïƒ = âˆšVar(X)
```

---

## ğŸ’» Python ì‹¤ìŠµ

```python
import numpy as np
import matplotlib.pyplot as plt

# ì •ê·œë¶„í¬ ìƒì„±
mu, sigma = 0, 1
samples = np.random.normal(mu, sigma, 10000)

print("=== ì •ê·œë¶„í¬ ===")
print(f"ì´ë¡ : Î¼={mu}, Ïƒ={sigma}")
print(f"ìƒ˜í”Œ: Î¼={np.mean(samples):.4f}, Ïƒ={np.std(samples):.4f}\n")

# íˆìŠ¤í† ê·¸ë¨
plt.figure(figsize=(10, 6))
plt.hist(samples, bins=50, density=True, alpha=0.7, label='ìƒ˜í”Œ')

x = np.linspace(-4, 4, 100)
y = (1/np.sqrt(2*np.pi*sigma**2)) * np.exp(-(x-mu)**2/(2*sigma**2))
plt.plot(x, y, 'r-', linewidth=2, label='ì´ë¡ ')

plt.xlabel('x')
plt.ylabel('í™•ë¥ ë°€ë„')
plt.title('ì •ê·œë¶„í¬ N(0, 1)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('normal_distribution.png', dpi=150)
print("ì‹œê°í™” ì €ì¥!")
```

---

## ğŸ”— LLM ì—°ê²°ì 

### ì„ë² ë”© ì´ˆê¸°í™”
```python
# PyTorch
embedding = nn.Embedding(vocab_size, embed_dim)
# ë‚´ë¶€ì ìœ¼ë¡œ N(0, 1)ë¡œ ì´ˆê¸°í™”

ê°€ì¤‘ì¹˜ë„ ì •ê·œë¶„í¬ë¡œ ì´ˆê¸°í™”!
```

---

## ğŸ“ í•µì‹¬ ìš”ì•½

1. **ì •ê·œë¶„í¬**: N(Î¼, ÏƒÂ²)
2. **í‰ê· **: ì¤‘ì‹¬
3. **ë¶„ì‚°**: í¼ì§„ ì •ë„

### ë‹¤ìŒ í•™ìŠµ
- **Day 31**: ì¤‘ê°„ ë³µìŠµ

---

**ì •ê·œë¶„í¬ëŠ” ìì—°ê³¼ AIì—ì„œ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤!**
