# Day 19: í–‰ë ¬ì‹ê³¼ ë…¸ë¦„ (1ì‹œê°„)

## ğŸ“š í•™ìŠµ ëª©í‘œ
- í–‰ë ¬ì‹(determinant)ì˜ ì˜ë¯¸ ì´í•´í•˜ê¸°
- í–‰ë ¬ ë…¸ë¦„ì˜ ì¢…ë¥˜ì™€ ê³„ì‚° ë°©ë²• ìµíˆê¸°
- ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ê³¼ì˜ ì—°ê²° ì´í•´í•˜ê¸°

---

## ğŸ¯ ê°•ì˜ ì£¼ì œ
**"í–‰ë ¬ì˜ í¬ê¸°ì™€ ë³€í™˜ì˜ ì²™ë„"**

---

## ğŸ“– í•µì‹¬ ê°œë…

### 1. í–‰ë ¬ì‹ (Determinant)

**ê¸°í•˜í•™ì  ì˜ë¯¸**:
```
det(A) = ì„ í˜• ë³€í™˜ Aê°€ ë¶€í”¼ë¥¼ ì–¼ë§ˆë‚˜ ë³€í™”ì‹œí‚¤ëŠ”ê°€
```

**2Ã—2 ê³µì‹**:
```
A = [a  b]
    [c  d]

det(A) = ad - bc
```

**3Ã—3 ê³µì‹** (ì‚¬ë£¨ìŠ¤ ë²•ì¹™):
```
A = [a  b  c]
    [d  e  f]
    [g  h  i]

det(A) = aei + bfg + cdh - ceg - afh - bdi
```

**ì„±ì§ˆ**:
```
det(AB) = det(A) Ã— det(B)
det(A^T) = det(A)
det(Aâ»Â¹) = 1/det(A)
det(kA) = k^n det(A)  (n: í–‰ë ¬ í¬ê¸°)
```

---

### 2. í–‰ë ¬ì‹ì˜ ì˜ë¯¸

**det(A) > 0**: ë°©í–¥ ìœ ì§€
**det(A) < 0**: ë°©í–¥ ë°˜ì „
**det(A) = 0**: ì°¨ì› ì¶•ì†Œ (ì—­í–‰ë ¬ ì—†ìŒ)

**ì˜ˆì‹œ**:
```
# ë‹¨ìœ„í–‰ë ¬
I = [1  0]    det(I) = 1  (ë³€í™” ì—†ìŒ)
    [0  1]

# 2ë°° í™•ëŒ€
S = [2  0]    det(S) = 4  (ë©´ì  4ë°°)
    [0  2]

# íŠ¹ì´í–‰ë ¬ (singular)
A = [1  2]    det(A) = 0  (í•œ ì§ì„ ìœ¼ë¡œ ì¶•ì†Œ)
    [2  4]
```

---

### 3. í–‰ë ¬ ë…¸ë¦„ (Matrix Norm)

**Frobenius ë…¸ë¦„** (ê°€ì¥ í”í•¨):
```
||A||_F = âˆš(Î£áµ¢â±¼ aáµ¢â±¼Â²)

ëª¨ë“  ì›ì†Œì˜ ì œê³±í•©ì˜ ì œê³±ê·¼
```

**ì˜ˆì‹œ**:
```
A = [1  2]
    [3  4]

||A||_F = âˆš(1Â² + 2Â² + 3Â² + 4Â²)
        = âˆš30
        â‰ˆ 5.48
```

**ìŠ¤í™íŠ¸ëŸ¼ ë…¸ë¦„** (2-ë…¸ë¦„):
```
||A||â‚‚ = ìµœëŒ€ íŠ¹ì´ê°’
       = âˆš(A^T Aì˜ ìµœëŒ€ ê³ ìœ ê°’)
```

**ê¸°íƒ€ ë…¸ë¦„**:
```
||A||â‚ = ê° ì—´ì˜ í•©ì˜ ìµœëŒ“ê°’
||A||âˆ = ê° í–‰ì˜ í•©ì˜ ìµœëŒ“ê°’
```

---

### 4. ì¡°ê±´ìˆ˜ (Condition Number)

**ì •ì˜**:
```
Îº(A) = ||A|| Ã— ||Aâ»Â¹||
```

**ì˜ë¯¸**:
- ìˆ˜ì¹˜ ì•ˆì •ì„±ì˜ ì²™ë„
- í° ì¡°ê±´ìˆ˜ = ë¶ˆì•ˆì •
- ì‘ì€ ì¡°ê±´ìˆ˜ = ì•ˆì •

**ì˜ˆì‹œ**:
```
ì˜ ì¡°ê±´ì§€ì–´ì§„ í–‰ë ¬ (well-conditioned):
Îº(A) â‰ˆ 1

ë‚˜ì˜ê²Œ ì¡°ê±´ì§€ì–´ì§„ í–‰ë ¬ (ill-conditioned):
Îº(A) >> 1
```

---

## ğŸ’» Python ì‹¤ìŠµ

### ì‹¤ìŠµ 1: í–‰ë ¬ì‹ ê³„ì‚°
```python
import numpy as np

# 2Ã—2 í–‰ë ¬
A = np.array([[3, 1],
              [2, 4]])

print("=== í–‰ë ¬ì‹ ===")
print(f"A =\n{A}\n")

# í–‰ë ¬ì‹
det_A = np.linalg.det(A)
print(f"det(A) = {det_A:.4f}\n")

# ìˆ˜ë™ ê³„ì‚° (2Ã—2)
det_manual = A[0,0]*A[1,1] - A[0,1]*A[1,0]
print(f"ìˆ˜ë™ ê³„ì‚°: {det_manual}\n")

# íŠ¹ì´í–‰ë ¬ (singular)
B = np.array([[1, 2],
              [2, 4]])
det_B = np.linalg.det(B)
print(f"B =\n{B}")
print(f"det(B) = {det_B:.10f}  (â‰ˆ 0)")
print("â†’ BëŠ” ì—­í–‰ë ¬ì´ ì—†ìŒ!")
```

### ì‹¤ìŠµ 2: í–‰ë ¬ ë…¸ë¦„
```python
import numpy as np

A = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]])

print("=== í–‰ë ¬ ë…¸ë¦„ ===")
print(f"A =\n{A}\n")

# Frobenius ë…¸ë¦„
norm_F = np.linalg.norm(A, 'fro')
print(f"||A||_F = {norm_F:.4f}")

# ìˆ˜ë™ ê³„ì‚°
norm_F_manual = np.sqrt(np.sum(A**2))
print(f"ìˆ˜ë™ ê³„ì‚°: {norm_F_manual:.4f}\n")

# 2-ë…¸ë¦„ (ìŠ¤í™íŠ¸ëŸ¼ ë…¸ë¦„)
norm_2 = np.linalg.norm(A, 2)
print(f"||A||â‚‚ = {norm_2:.4f}\n")

# 1-ë…¸ë¦„
norm_1 = np.linalg.norm(A, 1)
print(f"||A||â‚ = {norm_1:.4f}\n")

# inf-ë…¸ë¦„
norm_inf = np.linalg.norm(A, np.inf)
print(f"||A||âˆ = {norm_inf:.4f}")
```

### ì‹¤ìŠµ 3: ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ ì‹œë®¬ë ˆì´ì…˜
```python
import numpy as np

def clip_gradient_norm(grad, max_norm):
    """ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ í´ë¦¬í•‘"""
    grad_norm = np.linalg.norm(grad)

    if grad_norm > max_norm:
        # í´ë¦¬í•‘
        grad = grad * (max_norm / grad_norm)
        clipped = True
    else:
        clipped = False

    return grad, grad_norm, clipped

# ê·¸ë˜ë””ì–¸íŠ¸ (ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ì˜ ê¸°ìš¸ê¸°)
gradients = [
    np.array([1.0, 2.0, 3.0]),
    np.array([10.0, 20.0, 30.0]),
    np.array([0.1, 0.2, 0.3])
]

max_norm = 5.0

print(f"=== ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (max_norm={max_norm}) ===\n")

for i, grad in enumerate(gradients):
    clipped_grad, original_norm, was_clipped = clip_gradient_norm(grad.copy(), max_norm)
    new_norm = np.linalg.norm(clipped_grad)

    print(f"ê·¸ë˜ë””ì–¸íŠ¸ {i+1}:")
    print(f"  ì›ë³¸: {grad}")
    print(f"  ||grad|| = {original_norm:.4f}")

    if was_clipped:
        print(f"  âš ï¸ í´ë¦¬í•‘ë¨!")
        print(f"  í´ë¦¬í•‘ í›„: {clipped_grad}")
        print(f"  ||clipped|| = {new_norm:.4f}")
    else:
        print(f"  âœ“ í´ë¦¬í•‘ ë¶ˆí•„ìš”")
    print()
```

---

## âœï¸ ì† ê³„ì‚° ì—°ìŠµ

### ì—°ìŠµ 1: í–‰ë ¬ì‹
```
A = [2  3]
    [1  4]

det(A) = 2Ã—4 - 3Ã—1 = 8 - 3 = 5
```

### ì—°ìŠµ 2: Frobenius ë…¸ë¦„
```
A = [1  2]
    [3  4]

||A||_F = âˆš(1Â² + 2Â² + 3Â² + 4Â²)
        = âˆš(1 + 4 + 9 + 16)
        = âˆš30
```

### ì—°ìŠµ 3: ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
```
grad = [3, 4]  (ë…¸ë¦„ = 5)
max_norm = 2

grad_clipped = grad Ã— (2/5) = [1.2, 1.6]

í™•ì¸: ||[1.2, 1.6]|| = âˆš(1.44 + 2.56) = 2 âœ“
```

---

## ğŸ”— LLM ì—°ê²°ì 

### 1. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
```python
# PyTorch
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# í­ì£¼(exploding gradient)ë¥¼ ë°©ì§€
# ì•ˆì •ì ì¸ í•™ìŠµ
```

### 2. Layer Normalization
```
# Frobenius ë…¸ë¦„ìœ¼ë¡œ ì •ê·œí™”
x_normalized = x / ||x||_F

Transformerì—ì„œ í•„ìˆ˜
```

### 3. ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
```
# Xavier/He ì´ˆê¸°í™”
# í–‰ë ¬ì˜ í¬ê¸°(ë…¸ë¦„)ë¥¼ ê³ ë ¤í•˜ì—¬ ì´ˆê¸°í™”
# ê¸°ìš¸ê¸° ì†Œì‹¤/í­ì£¼ ë°©ì§€
```

---

## âœ… ì²´í¬í¬ì¸íŠ¸

- [ ] **2Ã—2 í–‰ë ¬ì‹ì„ ê³„ì‚°í•  ìˆ˜ ìˆë‚˜ìš”?**

- [ ] **Frobenius ë…¸ë¦„ì„ ê³„ì‚°í•  ìˆ˜ ìˆë‚˜ìš”?**

- [ ] **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì˜ ì›ë¦¬ë¥¼ ì´í•´í–ˆë‚˜ìš”?**

- [ ] **í–‰ë ¬ì‹ = 0ì˜ ì˜ë¯¸ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‚˜ìš”?**

---

## ğŸ“ í•µì‹¬ ìš”ì•½

1. **í–‰ë ¬ì‹**: det(A) = ë¶€í”¼ ë³€í™” ë¹„ìœ¨
2. **Frobenius ë…¸ë¦„**: ||A||_F = âˆš(Î£ aáµ¢â±¼Â²)
3. **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘**: grad Ã— (max_norm / ||grad||)
4. **ìˆ˜ì¹˜ ì•ˆì •ì„±**: ì¡°ê±´ìˆ˜, ë…¸ë¦„ ê´€ë¦¬ ì¤‘ìš”

### ë‹¤ìŒ í•™ìŠµ
- **Day 20**: ì„ í˜•ëŒ€ìˆ˜ ìµœì¢… í”„ë¡œì íŠ¸

---

**ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!** ğŸ‰

**ë…¸ë¦„ì€ ì‹ ê²½ë§ ì•ˆì •ì„±ì˜ í•µì‹¬ì…ë‹ˆë‹¤!**
